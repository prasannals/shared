Not all visual tasks have a clear objective. Sometimes, we're performing exploratory search for patterns in visual data. I'm interested in developing interpretable visual models which act as a tool for better decision making for humans in these situations. Imagine training a visual model on satellite images of clouds to classify whether it's going to rain today at a particular location. By interpreting the model's decision making, we might learn visual patterns which are important for the task. This enables exploratory analysis of a system even if we're not interested in the task itself(rain prediction). This can be applied to medical context too. To learn hidden patterns in x Ray images or cells that, perhaps, even doctors missed. As a part of Research Methods course(691DD), I'm working on visual interpretation of regression models which use CNN backbone. Task involves extending GradCAM algorithm for regression and possibly even extending the algorithm generally. 

Another area of interest is using visual recognition (classification, localization) to help in situations where we simply lack the human resources to perform the task. For example, if my bicycle gets stolen in Amherst, police likely won't do much about it because they lack the human resource to solve the huge number of crimes. Visual recognition and automation in that context, perhaps to recognize crime, could deeply improve humans life. In a nutshell - automation to aid in tasks we don't have the resources to perform rather than to replace us in tasks that we can perform.
